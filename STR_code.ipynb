{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85S7i_iU1pRz",
        "outputId": "6a3f3596-71fe-4e8c-c3a5-239adbb45c86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import fnmatch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import string\n",
        "import time\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.activations import relu, sigmoid, softmax\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slTsQEHE1pR0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#ignore warnings in the output\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z85jAzu-1pR0",
        "outputId": "93d43aa9-dd21-45ec-8ff1-6a940d1e0a30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 472655688989744329\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 3209412608\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 5197767360891115092\n",
            "physical_device_desc: \"device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "# Check all available devices if GPU is available\n",
        "print(device_lib.list_local_devices())\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIT1P-ed1pR1"
      },
      "source": [
        "wget https://www.robots.ox.ac.uk/~vgg/data/text/mjsynth.tar.gz\n",
        "\n",
        "tar -xvzf mjsynth.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sM41zxT1pR1"
      },
      "outputs": [],
      "source": [
        "# char_list:   'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "# total number of our output classes: len(char_list)\n",
        "char_list = string.ascii_letters+string.digits\n",
        "\n",
        "def encode_to_labels(txt):\n",
        "    # encoding each output word into digits\n",
        "    dig_lst = []\n",
        "    for index, char in enumerate(txt):\n",
        "        try:\n",
        "            dig_lst.append(char_list.index(char))\n",
        "        except:\n",
        "            print(char)\n",
        "\n",
        "    return dig_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYtAxGBL1pR1"
      },
      "outputs": [],
      "source": [
        "path = 'mjsynth.tar/mnt/ramdisk/max/90kDICT32px'\n",
        "\n",
        "\n",
        "# lists for training dataset\n",
        "training_img = []\n",
        "training_txt = []\n",
        "train_input_length = []\n",
        "train_label_length = []\n",
        "orig_txt = []\n",
        "\n",
        "#lists for validation dataset\n",
        "valid_img = []\n",
        "valid_txt = []\n",
        "valid_input_length = []\n",
        "valid_label_length = []\n",
        "valid_orig_txt = []\n",
        "\n",
        "max_label_len = 0\n",
        "\n",
        "i =1\n",
        "flag = 0\n",
        "\n",
        "for root, dirnames, filenames in os.walk(path):\n",
        "\n",
        "    for f_name in fnmatch.filter(filenames, '*.jpg'):\n",
        "        # read input image and convert into gray scale image\n",
        "        img = cv2.cvtColor(cv2.imread(os.path.join(root, f_name)), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # convert each image of shape (32, 128, 1)\n",
        "        w, h = img.shape\n",
        "        if h > 128 or w > 32:\n",
        "            continue\n",
        "        if w < 32:\n",
        "            add_zeros = np.ones((32-w, h))*255\n",
        "            img = np.concatenate((img, add_zeros))\n",
        "\n",
        "        if h < 128:\n",
        "            add_zeros = np.ones((32, 128-h))*255\n",
        "            img = np.concatenate((img, add_zeros), axis=1)\n",
        "        img = np.expand_dims(img , axis = 2)\n",
        "\n",
        "        # Normalize each image\n",
        "        img = img/255.\n",
        "\n",
        "        # get the text from the image\n",
        "        txt = f_name.split('_')[1]\n",
        "\n",
        "        # compute maximum length of the text\n",
        "        if len(txt) > max_label_len:\n",
        "            max_label_len = len(txt)\n",
        "\n",
        "\n",
        "        # split the 150000 data into validation and training dataset as 10% and 90% respectively\n",
        "        if i%10 == 0:\n",
        "            valid_orig_txt.append(txt)\n",
        "            valid_label_length.append(len(txt))\n",
        "            valid_input_length.append(31)\n",
        "            valid_img.append(img)\n",
        "            valid_txt.append(encode_to_labels(txt))\n",
        "        else:\n",
        "            orig_txt.append(txt)\n",
        "            train_label_length.append(len(txt))\n",
        "            train_input_length.append(31)\n",
        "            training_img.append(img)\n",
        "            training_txt.append(encode_to_labels(txt))\n",
        "\n",
        "        # break the loop if total data is 150000\n",
        "        if i == 150000:\n",
        "            flag = 1\n",
        "            break\n",
        "        i+=1\n",
        "    if flag == 1:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhXGuUfg1pR1"
      },
      "outputs": [],
      "source": [
        "# pad each output label to maximum text length\n",
        "\n",
        "train_padded_txt = pad_sequences(training_txt, maxlen=max_label_len, padding='post', value = len(char_list))\n",
        "valid_padded_txt = pad_sequences(valid_txt, maxlen=max_label_len, padding='post', value = len(char_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YUU1aJX1pR2"
      },
      "outputs": [],
      "source": [
        "# input with shape of height=32 and width=128\n",
        "inputs = Input(shape=(32,128,1))\n",
        "\n",
        "# convolution layer with kernel size (3,3)\n",
        "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
        "# poolig layer with kernel size (2,2)\n",
        "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
        "\n",
        "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
        "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
        "\n",
        "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
        "\n",
        "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
        "# poolig layer with kernel size (2,1)\n",
        "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
        "\n",
        "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
        "# Batch normalization layer\n",
        "batch_norm_5 = BatchNormalization()(conv_5)\n",
        "\n",
        "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
        "batch_norm_6 = BatchNormalization()(conv_6)\n",
        "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
        "\n",
        "conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
        "\n",
        "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
        "\n",
        "# bidirectional LSTM layers with units=128\n",
        "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
        "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
        "\n",
        "outputs = Dense(len(char_list)+1, activation = 'softmax')(blstm_2)\n",
        "\n",
        "# model to be used at test time\n",
        "act_model = Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LanRh-Qw1pR2",
        "outputId": "fc1a4b9f-4f4b-4e3b-dede-6155d90ed331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32, 128, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 128, 64)       640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 32, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 32, 256)        295168    \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 32, 256)        590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 32, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 1, 31, 512)        1049088   \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 31, 512)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 31, 256)           656384    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 31, 256)           394240    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 31, 63)            16191     \n",
            "=================================================================\n",
            "Total params: 6,619,711\n",
            "Trainable params: 6,617,663\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "act_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0_99kik1pR2"
      },
      "outputs": [],
      "source": [
        "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
        "\n",
        "#model to be used at training time\n",
        "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6X2LnKs1pR2"
      },
      "outputs": [],
      "source": [
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
        "\n",
        "filepath=\"best_model.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXwU3BNk1pR3"
      },
      "outputs": [],
      "source": [
        "training_img = np.array(training_img)\n",
        "train_input_length = np.array(train_input_length)\n",
        "train_label_length = np.array(train_label_length)\n",
        "\n",
        "valid_img = np.array(valid_img)\n",
        "valid_input_length = np.array(valid_input_length)\n",
        "valid_label_length = np.array(valid_label_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9LkG1Ek1pR3",
        "outputId": "5df5c3ff-4dfd-476d-a659-a801fbbf0973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 135000 samples, validate on 15000 samples\n",
            "Epoch 1/10\n",
            "135000/135000 [==============================] - 586s 4ms/step - loss: 27.5512 - val_loss: 26.9004\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 26.90039, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "135000/135000 [==============================] - 612s 5ms/step - loss: 26.1934 - val_loss: 26.9729\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 26.90039\n",
            "Epoch 3/10\n",
            "135000/135000 [==============================] - 619s 5ms/step - loss: 21.8621 - val_loss: 21.6336\n",
            "\n",
            "Epoch 00003: val_loss improved from 26.90039 to 21.63363, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "135000/135000 [==============================] - 610s 5ms/step - loss: 8.3180 - val_loss: 5.4096\n",
            "\n",
            "Epoch 00004: val_loss improved from 21.63363 to 5.40958, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "135000/135000 [==============================] - 640s 5ms/step - loss: 4.3365 - val_loss: 3.9244\n",
            "\n",
            "Epoch 00005: val_loss improved from 5.40958 to 3.92440, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "135000/135000 [==============================] - 658s 5ms/step - loss: 3.4060 - val_loss: 5.2163\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 3.92440\n",
            "Epoch 7/10\n",
            "135000/135000 [==============================] - 608s 5ms/step - loss: 3.2047 - val_loss: 3.4186\n",
            "\n",
            "Epoch 00007: val_loss improved from 3.92440 to 3.41857, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "135000/135000 [==============================] - 634s 5ms/step - loss: 2.6313 - val_loss: 3.1864\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.41857 to 3.18637, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "135000/135000 [==============================] - 677s 5ms/step - loss: 2.3521 - val_loss: 3.0067\n",
            "\n",
            "Epoch 00009: val_loss improved from 3.18637 to 3.00666, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "135000/135000 [==============================] - 702s 5ms/step - loss: 2.1227 - val_loss: 3.0125\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 3.00666\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x299611aa048>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 256\n",
        "epochs = 10\n",
        "model.fit(x=[training_img, train_padded_txt, train_input_length, train_label_length], y=np.zeros(len(training_img)), batch_size=batch_size, epochs = epochs, validation_data = ([valid_img, valid_padded_txt, valid_input_length, valid_label_length], [np.zeros(len(valid_img))]), verbose = 1, callbacks = callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww2OZjC41pR3",
        "outputId": "710eaac3-c76e-4c93-9ac8-3e0f056ff7ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original_text =   Expend\n",
            "predicted text = Expend\n",
            "\n",
            "original_text =   RAKE\n",
            "predicted text = RAKE\n",
            "\n",
            "original_text =   IMAM\n",
            "predicted text = MAM\n",
            "\n",
            "original_text =   kraft\n",
            "predicted text = kralt\n",
            "\n",
            "original_text =   deceleration\n",
            "predicted text = deceleration\n",
            "\n",
            "original_text =   FOXHUNTING\n",
            "predicted text = Foxhunting\n",
            "\n",
            "original_text =   Renaud\n",
            "predicted text = Renaud\n",
            "\n",
            "original_text =   Trenchant\n",
            "predicted text = Trenchant\n",
            "\n",
            "original_text =   HOD\n",
            "predicted text = HOD\n",
            "\n",
            "original_text =   sculpt\n",
            "predicted text = sculpt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# load the saved best model weights\n",
        "act_model.load_weights('best_model.hdf5')\n",
        "\n",
        "# predict outputs on validation images\n",
        "prediction = act_model.predict(valid_img[:10])\n",
        "\n",
        "# use CTC decoder\n",
        "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
        "                         greedy=True)[0][0])\n",
        "\n",
        "# see the results\n",
        "i = 0\n",
        "for x in out:\n",
        "    print(\"original_text =  \", valid_orig_txt[i])\n",
        "    print(\"predicted text = \", end = '')\n",
        "    for p in x:\n",
        "        if int(p) != -1:\n",
        "            print(char_list[int(p)], end = '')\n",
        "    print('\\n')\n",
        "    i+=1"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}